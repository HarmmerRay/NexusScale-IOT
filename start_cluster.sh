#!/bin/bash

# é›†ç¾¤æœåŠ¡å¯åŠ¨è„šæœ¬
# åœ¨masteræœºå™¨(192.168.56.10)ä¸Šæ‰§è¡Œ
# ä½œè€…: NexusScale-IOT
# æè¿°: å¯åŠ¨4å°è™šæ‹Ÿæœºç»„æˆçš„å¤§æ•°æ®é›†ç¾¤çš„æ‰€æœ‰æœåŠ¡

# è®¾ç½®é¢œè‰²è¾“å‡º
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# é›†ç¾¤èŠ‚ç‚¹IP
MASTER="192.168.56.10"
SLAVE1="192.168.56.11" 
SLAVE2="192.168.56.12"
SLAVE3="192.168.56.13"
SLAVES=("$SLAVE1" "$SLAVE2" "$SLAVE3")

# ç»„ä»¶è·¯å¾„é…ç½®
BASE_DIR="/home/zy/ä¸‹è½½"
KAFKA_HOME="$BASE_DIR/kafka_2.13-3.0.0"
NODE_EXPORTER_HOME="$BASE_DIR/node_exporter-1.9.0.linux-amd64"
PROMETHEUS_HOME="$BASE_DIR/prometheus-3.2.1.linux-amd64"
GRAFANA_HOME="$BASE_DIR/grafana-v11.3.3"
HADOOP_HOME="$BASE_DIR/hadoop-3.1.3"
HBASE_HOME="$BASE_DIR/hbase-2.2.2"
ZOOKEEPER_HOME="$BASE_DIR/zookeeper-3.4.14"

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${GREEN}[INFO]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_step() {
    echo -e "${BLUE}[STEP]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

# æ£€æŸ¥SSHè¿æ¥
check_ssh_connectivity() {
    log_step "æ£€æŸ¥SSHè¿æ¥..."
    
    for slave in "${SLAVES[@]}"; do
        if ssh -o ConnectTimeout=5 $slave "echo 'SSH OK'" >/dev/null 2>&1; then
            log_info "SSHè¿æ¥åˆ° $slave æˆåŠŸ"
        else
            log_error "æ— æ³•SSHè¿æ¥åˆ° $slave"
            exit 1
        fi
    done
}

# æ¸…ç†æœ¬åœ°æ•°æ®ï¼ˆä¸éœ€è¦æœåŠ¡è¿è¡Œï¼‰
cleanup_local_data() {
    log_step "æ¸…ç†æœ¬åœ°æ•°æ®..."
    
    # æ¸…ç†æ‰€æœ‰èŠ‚ç‚¹çš„æœ¬åœ°HBaseå’ŒKafkaæ•°æ®
    log_info "æ¸…ç†æœ¬åœ°HBaseå’ŒKafkaæ•°æ®..."
    
    # æ¸…ç†masterèŠ‚ç‚¹
    rm -rf /tmp/hbase-* 2>/dev/null || true
    rm -rf $HBASE_HOME/logs/* 2>/dev/null || true
    
    # æ¸…ç†slaveèŠ‚ç‚¹
    for slave in "${SLAVES[@]}"; do
        log_info "æ¸…ç† $slave èŠ‚ç‚¹æ•°æ®..."
        ssh $slave "
            BASE_DIR='/home/zy/ä¸‹è½½'
            HBASE_HOME='\$BASE_DIR/hbase-2.2.2'
            rm -rf /tmp/hbase-* 2>/dev/null || true
            rm -rf \$HBASE_HOME/logs/* 2>/dev/null || true
            rm -rf /tmp/kafka-logs/* 2>/dev/null || true
            find /tmp -name 'meta.properties' -delete 2>/dev/null || true
        " &
    done
    wait
    
    log_info "æœ¬åœ°æ•°æ®æ¸…ç†å®Œæˆ"
}

# æ¸…ç†HDFSå’ŒZooKeeperä¸­çš„æ—§æ•°æ®ï¼ˆéœ€è¦æœåŠ¡è¿è¡Œï¼‰
cleanup_service_data() {
    log_step "æ¸…ç†HDFSå’ŒZooKeeperä¸­çš„æ—§æ•°æ®..."
    
    # æ¸…ç†HDFSä¸­çš„HBaseç›®å½•
    log_info "æ¸…ç†HDFSä¸­çš„HBaseç›®å½•..."
    source /etc/profile
    hdfs dfs -rm -r -f /hbase 2>/dev/null || true
    
    # æ¸…ç†ZooKeeperä¸­çš„HBaseå’ŒKafkaèŠ‚ç‚¹
    log_info "æ¸…ç†ZooKeeperæ•°æ®..."
    ssh $SLAVE1 "source /etc/profile && zkCli.sh <<EOF
ls /
rmr /hbase 2>/dev/null || true
rmr /brokers 2>/dev/null || true
rmr /admin 2>/dev/null || true
rmr /isr_change_notification 2>/dev/null || true
rmr /consumers 2>/dev/null || true
rmr /config 2>/dev/null || true
rmr /controller_epoch 2>/dev/null || true
rmr /cluster 2>/dev/null || true
rmr /feature 2>/dev/null || true
rmr /latest_producer_id_block 2>/dev/null || true
rmr /log_dir_event_notification 2>/dev/null || true
quit
EOF" 2>/dev/null || true
    
    log_info "æœåŠ¡æ•°æ®æ¸…ç†å®Œæˆ"
}

# å¯åŠ¨Hadoop
start_hadoop() {
    log_step "å¯åŠ¨Hadoop..."
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    source /etc/profile
    
    log_info "å¯åŠ¨HDFS..."
    start-dfs.sh
    
    log_info "å¯åŠ¨YARN..."
    start-yarn.sh
    
    # ç­‰å¾…æœåŠ¡å¯åŠ¨
    sleep 10
    
    # éªŒè¯HadoopæœåŠ¡
    if jps | grep -q "NameNode"; then
        log_info "HDFS NameNode å¯åŠ¨æˆåŠŸ"
    else
        log_error "HDFS NameNode å¯åŠ¨å¤±è´¥"
        return 1
    fi
    
    if jps | grep -q "ResourceManager"; then
        log_info "YARN ResourceManager å¯åŠ¨æˆåŠŸ"
    else
        log_error "YARN ResourceManager å¯åŠ¨å¤±è´¥"
        return 1
    fi
    
    log_info "Hadoopå¯åŠ¨å®Œæˆ"
    log_info "Hadoop Web UI: http://$MASTER:9870 (HDFS)"
    log_info "YARN Web UI: http://$MASTER:8088 (YARN)"
}

# å¯åŠ¨ZooKeeper
start_zookeeper() {
    log_step "å¯åŠ¨ZooKeeper..."
    
    for slave in "${SLAVES[@]}"; do
        log_info "åœ¨ $slave ä¸Šå¯åŠ¨ZooKeeper..."
        ssh $slave "source /etc/profile && zkServer.sh start" &
    done
    wait
    
    # ç­‰å¾…ZooKeeperå¯åŠ¨
    sleep 15
    
    # éªŒè¯ZooKeeperçŠ¶æ€
    for slave in "${SLAVES[@]}"; do
        log_info "æ£€æŸ¥ $slave ä¸Šçš„ZooKeeperçŠ¶æ€..."
        if ssh $slave "source /etc/profile && zkServer.sh status" | grep -q "Mode:"; then
            log_info "$slave ZooKeeper å¯åŠ¨æˆåŠŸ"
        else
            log_error "$slave ZooKeeper å¯åŠ¨å¤±è´¥"
            return 1
        fi
    done
    
    log_info "ZooKeeperé›†ç¾¤å¯åŠ¨å®Œæˆ"
}

# å¯åŠ¨HBase
start_hbase() {
    log_step "å¯åŠ¨HBase..."
    
    # åŠ è½½ç¯å¢ƒå˜é‡
    source /etc/profile
    
    log_info "å¯åŠ¨HBaseé›†ç¾¤..."
    start-hbase.sh
    
    # ç­‰å¾…HBaseå¯åŠ¨
    sleep 20
    
    # éªŒè¯HBaseæœåŠ¡
    if jps | grep -q "HMaster"; then
        log_info "HBase Master å¯åŠ¨æˆåŠŸ"
    else
        log_error "HBase Master å¯åŠ¨å¤±è´¥"
        return 1
    fi
    
    # åˆ›å»ºIoTä¼ æ„Ÿå™¨æ•°æ®è¡¨
    log_info "åˆ›å»ºHBaseè¡¨..."
    source /etc/profile
    hbase shell <<EOF
create 'iot_sensor_data','cf1'
list
exit
EOF
    
    log_info "HBaseå¯åŠ¨å®Œæˆ"
    log_info "HBase Web UI: http://$MASTER:16010"
}

# å¯åŠ¨Kafka
start_kafka() {
    log_step "å¯åŠ¨Kafka..."
    
    for slave in "${SLAVES[@]}"; do
        log_info "åœ¨ $slave ä¸Šå¯åŠ¨Kafka..."
        ssh $slave "
            BASE_DIR='/home/zy/ä¸‹è½½'
            KAFKA_HOME='\$BASE_DIR/kafka_2.13-3.0.0'
            cd \$KAFKA_HOME && ./bin/kafka-server-start.sh -daemon config/server.properties
        " &
    done
    wait
    
    # ç­‰å¾…Kafkaå¯åŠ¨
    sleep 15
    
    # éªŒè¯KafkaæœåŠ¡
    for slave in "${SLAVES[@]}"; do
        if ssh $slave "jps | grep -q Kafka"; then
            log_info "$slave Kafka å¯åŠ¨æˆåŠŸ"
        else
            log_error "$slave Kafka å¯åŠ¨å¤±è´¥"
            return 1
        fi
    done
    
    # åˆ›å»ºIoTä¼ æ„Ÿå™¨æ•°æ®ä¸»é¢˜
    log_info "åˆ›å»ºKafkaä¸»é¢˜..."
    source /etc/profile
    $KAFKA_HOME/bin/kafka-topics.sh --create --bootstrap-server $SLAVE1:9092,$SLAVE2:9092,$SLAVE3:9092 \
        --topic sensor_data_topic --partitions 3 --replication-factor 2 2>/dev/null || true
    
    # éªŒè¯ä¸»é¢˜åˆ›å»º
    log_info "éªŒè¯Kafkaä¸»é¢˜..."
    $KAFKA_HOME/bin/kafka-topics.sh --list --bootstrap-server $SLAVE1:9092,$SLAVE2:9092,$SLAVE3:9092
    
    log_info "Kafkaé›†ç¾¤å¯åŠ¨å®Œæˆ"
}

# å¯åŠ¨ç›‘æ§æœåŠ¡
start_monitoring() {
    log_step "å¯åŠ¨ç›‘æ§æœåŠ¡..."
    
    # å¯åŠ¨æ‰€æœ‰èŠ‚ç‚¹çš„Node Exporter
    log_info "å¯åŠ¨Node Exporter..."
    for node in $MASTER "${SLAVES[@]}"; do
        log_info "åœ¨ $node ä¸Šå¯åŠ¨Node Exporter..."
        if [ "$node" == "$MASTER" ]; then
            nohup $NODE_EXPORTER_HOME/node_exporter > /dev/null 2>&1 &
        else
            ssh $node "
                BASE_DIR='/home/zy/ä¸‹è½½'
                NODE_EXPORTER_HOME='\$BASE_DIR/node_exporter-1.9.0.linux-amd64'
                nohup \$NODE_EXPORTER_HOME/node_exporter > /dev/null 2>&1 &
            " &
        fi
    done
    wait
    
    # å¯åŠ¨Prometheus (ä»…åœ¨master)
    log_info "å¯åŠ¨Prometheus..."
    cd $PROMETHEUS_HOME
    nohup ./prometheus --config.file=prometheus.yml > /dev/null 2>&1 &
    
    # å¯åŠ¨Grafana (ä»…åœ¨master)
    log_info "å¯åŠ¨Grafana..."
    cd $GRAFANA_HOME/bin
    nohup ./grafana-server web > /dev/null 2>&1 &
    
    sleep 5
    
    log_info "ç›‘æ§æœåŠ¡å¯åŠ¨å®Œæˆ"
    log_info "Prometheus Web UI: http://$MASTER:9090"
    log_info "Grafana Web UI: http://$MASTER:3000 (admin/111111)"
}

# æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
show_cluster_status() {
    log_step "é›†ç¾¤çŠ¶æ€æ€»è§ˆ"
    echo
    echo "================================="
    echo "    é›†ç¾¤æœåŠ¡å¯åŠ¨å®Œæˆ!"
    echo "================================="
    echo
    echo "ğŸŒ Webç•Œé¢è®¿é—®åœ°å€:"
    echo "  ğŸ“Š Hadoop HDFS:    http://$MASTER:9870"
    echo "  ğŸ”§ YARN:           http://$MASTER:8088"  
    echo "  ğŸ—ƒï¸  HBase:          http://$MASTER:16010"
    echo "  ğŸ“ˆ Prometheus:     http://$MASTER:9090"
    echo "  ğŸ“‰ Grafana:        http://$MASTER:3000 (admin/111111)"
    echo
    echo "ğŸ”— æœåŠ¡è¿æ¥ä¿¡æ¯:"
    echo "  ğŸ“Š Kafka Brokers:  $SLAVE1:9092,$SLAVE2:9092,$SLAVE3:9092"
    echo "  ğŸ” ZooKeeper:      $SLAVE1:2181,$SLAVE2:2181,$SLAVE3:2181"
    echo "  ğŸ—ƒï¸  HBase:          $MASTER:16000"
    echo
    echo "ğŸš€ æ‰€æœ‰æœåŠ¡å·²æˆåŠŸå¯åŠ¨!"
    echo "================================="
}

# ä¸»å‡½æ•°
main() {
    echo "=================================================="
    echo "       NexusScale-IOT é›†ç¾¤å¯åŠ¨è„šæœ¬"
    echo "=================================================="
    echo
    
    # æ£€æŸ¥æ˜¯å¦åœ¨masterèŠ‚ç‚¹æ‰§è¡Œ
    current_ip=$(hostname -I | awk '{print $1}')
    if [ "$current_ip" != "$MASTER" ]; then
        log_warn "å»ºè®®åœ¨masterèŠ‚ç‚¹($MASTER)ä¸Šæ‰§è¡Œæ­¤è„šæœ¬"
    fi
    
    # æ‰§è¡Œå¯åŠ¨æµç¨‹
    check_ssh_connectivity
    cleanup_local_data           # å…ˆæ¸…ç†æœ¬åœ°æ•°æ®
    start_hadoop                 # å¯åŠ¨Hadoop
    start_zookeeper             # å¯åŠ¨ZooKeeper
    cleanup_service_data        # æ¸…ç†HDFSå’ŒZooKeeperä¸­çš„æ—§æ•°æ®
    start_hbase                 # å¯åŠ¨HBase
    start_kafka                 # å¯åŠ¨Kafka
    start_monitoring            # å¯åŠ¨ç›‘æ§æœåŠ¡
    show_cluster_status
    
    log_info "é›†ç¾¤å¯åŠ¨è„šæœ¬æ‰§è¡Œå®Œæˆ!"
}

# é”™è¯¯å¤„ç†
set -e
trap 'log_error "è„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯"; exit 1' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main "$@" 